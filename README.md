# 데모 시스템 개요

## 요구사항 개요
- 장소 검색 서비스 - 카카오 검색 API, 네이버 검색 API - 를 통해 각각 최대 5개씩, 총 10개의 키워드 관련 장소를 검색합니다.
- 검색 키워드 탑 랭킹 10
- 비기능 요구사항

## 산출물 구성
- 본 과제는 기능 요구사항 구현을 위해 web application, consumer appliction, kafka, database 4개의 구성요소로 설계하였습니다.
- 실제 구현은 web application과 consumer application 로직을 하나로 통합하여 단일 application 에서 동작하게 하며 database는 h2 db를 채용하였습니다.
- kafka는 로컬 도커환경에서 구동하도록 구성되어 있으며 "api-demo/local-demo-kafka" 경로에서 "docker-compose up -d" 명령어로 구동 가능합니다.   
- 어플리케이션은 openapi 사용을 위해 유효한 카카오 openapi appKey 및 네이버 client, secret을 Program argument 형태로 아래와 같이 전달합니다.
```
--kakao.appkey=xxxxxxxxxxx --naver.client=xxxxxxxx --naver.secret=xxxxxxxx
```

## cURL 테스트 코드

### 키워드 검색 기능 호출 예
```
curl --location --request GET 'http://localhost:8080/search?keyword=%EB%AF%B8%EA%B8%88%EC%97%AD'
```
### 키워드 검색 기능 응답 예
```
[
    {
        "name": "미금역 수인분당선",
        "address": "경기 성남시 분당구 금곡동 222"
    },
    {
        "name": "미금역 신분당선",
        "address": "경기 성남시 분당구 금곡동 222"
    },
   ... 중략 ...
]
```

### 키워드 랭킹 기능 호출 예
```
curl --location --request GET 'http://localhost:8080/search/rank10'
```
### 키워드 검색 기능 응답 예
```
[
    {
        "keyword": "미금역",
        "searchCount": 6
    },
    {
        "keyword": "카카오",
        "searchCount": 5
    },
    {
        "keyword": "은행",
        "searchCount": 5
    },
   ... 중략 ...
]
```

# 요구사항 구현 설명

## 기능 요구사항1 구현 설명

검색 기능의 경우 아래와 같이 크개 3가지 단계로 로직을 구성하였습니다.
1)단계 여러건의 api 호출, 2)단계 공통된데이터 압축, 3)단계 기준 3개를 적용하여 정렬

1)단계의 경우, 쓰레드풀을 활용한 병렬 호출로 진행합니다. 특정 api에서 실패가 났을때는 성공한 api만으로 데이터 구성 로직을 수행하도록 합니다.

1)단계에서 2)단계로 전달되는 데이터의 경우, 한쪽 api의 결과값이 기준치 이하일 경우, 다른 api 결과값에서 충당합니다.

2)단계 ~ 3단계) 구현의 경우, 데이터를 압축 / 정렬하는 부분을 추상화하여 문제를 해결합니다.

여러 api 결과에서 공통된 데이터를 뽑는 로직은 여러 이종 api사이의 유일 식별자가 존재하지 않습니다. 
지도 데이터의 경우, 주소지를 사용할 가능성이 있지만 같은 주소지 않에서도 세부적으로 장소가 나뉘는 경우가 존재합니다.
따라서 특정룰을 기반으로 동치 비교가 필요합니다. 여러가지 방법이 있지만, 해당 데모에서는 특수문자 및 공백을 제거한 장소명칭과 주소를 동시에 비교하여 같은 데이터인지 확인합니다.
이러한 동치 연산을 그대로 적용할 경우, 크기 n의 m개의 리스트에 대해서 진행할 경우 O(n^m)까지 연산이 많아 질 수 있으므로 다른 방법을 강구합니다.
물론 "정제된 장소 명칭 + 주소"를 unique key 값으로 판단하여 nlogn만큼의 성능을 낼 수 있지만, 장소 검색이라는 특성상 동치 연산이 확장될 가능성 ( e.g) 특정 필드의 유사도 적용)에서는 적용하기 힘듭니다.
따라서 동치 비교를 최소화 하는 방향으로 후보키k(data == data' 일때 k == k', 단 역은 성립안함)에 대한 해시맵을 만든후 같은 후보키를 가지는 데이터들 끼리 동치 비교를 하는 방법으로 구현하였습니다.

## 기능 요구사항2 구현 설명

키워드 검색의 경우, 카프카를 활용한 비동기 방식으로 구현하였습니다.

아래와 같은 대표적인 장점/단점으로 비동기 방식을 선택하였습니다.

장점1) 요청쓰레드에서 랭킹, 검색 기능이 모두 동작한다면 한쪽 기능의 장애가 다른 기능에 영향을 미칩니다. 비동기 처리를 통해서 최소 랭킹 기능의 장애가 전파되지 않는 장점이 있습니다.

장점2) 저장소 부하 감소, redis, rdbms 등 어떠한 저장소를 쓰더라도 요청쓰레드에서 동작을 한다면 write 연산에 대한 부하를 견뎌야합니다. 

단점1) 사용자 데이터에 대한 반영이 즉각적이지 않습니다. 
그러나 랭킹 기능은 즉각적인 수치반영에 대한 품질 요구사항이 강력하지 않을 것으로 생각하며, 컨슈머의 배치 처리를 통해서 일정 수준의 데이터 반영 속도를 보장하겠금 구현하였습니다.

rdbms를 선택한 이유

현재 구현된 기능은 키워드들을 영구 저장하는 상황에서 집계를 합니다.
키워드를 정제해서 저장을 한다하여도 저장소에 들어갈수 있는 데이터는 무한에 가깝습니다.
결국 추가적인 백엔드 시스템을 통해서 오래된 데이터를 flush 하거나, 압축하는등 데이터 정리 프로세스가 필요합니다.
이러한 프로세스를 구현하기 위해서는 랭킹 기능에 대한 상세 요구사항 ( e.g. 최근 몇달 기준만 보여주기, 일/월/년 단위로 집계 등등)에 맞는 다양한 전략이 검토될 것으로 생각됩니다.
이러한 확장측면에서 이벤트 데이터가 복잡해 질 수 있으며,  통계/집계등 복잡도 높은 데이터 연산이 필요할 가능성이 있기 때문에 rdbms를 선택하였습니다.

     
## 비기능 요구사항 설명

* 연동되는 api의 장애상황에 대해서 일부 api가 실패해도 성공한 데이터를 기반으로 검색 기능을 제공을 합니다.
  - 발전 방향 1: 외부 연동 포인트가 많은 경우, 서킷브레이커나 fallback 용도의 데이터에 대한 고민이 필요합니다.
  - 발전 방향 2: 랭킹시스템이 존재하기 때문에 해당 시스템을 활용하여 검색기능에 캐시를 도입할 가능성이 있습니다.

* 랭킹 시스템 운영에 대한 부하 저감을 위한 작업
  랭킹 데이터 조회에 대한 기본적인 캐시, 컨슈머 배치 처리를 통한 쿼리 최소화
  발전 방향1: 메시지 실패에 대한 고도화된 dlq 전략 및 컨슈머/프로듀서 옵션 튜닝
  발전 방향2: 키워드 검색 메시지 데이터에 대한 rdbms 스키마 구조 및 데이터 처리 최적화

## 해당 데모의 기능적 확장을 위한 방향성
해당 데모 버전에서는 동일 데이터 확인, 키워드 랭킹 로직등은 매우 기본적인 로직에 의해서 동작한다.
그러나 이러한 데이터 비교 / 추출등은 고도화될수록 서비스의 퀄리티에 큰 영향을 주기 때문에 코드 구조적으로 전체적인 아키텍처, 관련 기술 (e.g 검색..)에 대한 후발 작업이 필요하다.